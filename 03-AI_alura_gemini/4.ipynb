{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09840558",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "## *pip* commands\n",
    "pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa3108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70469b25",
   "metadata": {},
   "source": [
    "# API import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9227ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_path = \"APIKEY.txt\"\n",
    "with open(API_path, \"r\") as file:\n",
    "    APIKEY = file.read()\n",
    "\n",
    "client = genai.Client(api_key = APIKEY) # Allow to run every model that Google Gemini Supports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f359e",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033f05ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.5-flash-preview-04-17-thinking\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/gemini-2.0-flash-live-001\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list(): # See the available models\n",
    "    print(model.name)\n",
    "\n",
    "main_model = \"gemini-2.0-flash\" # Define the general model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133141fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the client, interact with the models, and with the models, interact with generation of content\n",
    "response = client.models.generate_content(model = main_model, contents = \"\")\n",
    "\n",
    "#response # Print response and metadata\n",
    "#response.text # Print only the model response\n",
    "#response.prompt_token_count # Amount of tokens used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fecc3a",
   "metadata": {},
   "source": [
    "# ChatBot\n",
    "The chatbot is a command that can be configured, constrained and store memory from previous inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = client.chats.create(model = main_model) # Creates a chat\n",
    "# Send message to the bot\n",
    "response = chat.send_message(\"\") # We can add constrains within the quotes, controling the response\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f46c2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# Create chatbot with configurations\n",
    "chat_config = types.GenerateContentConfig(\n",
    "    system_instruction = \"\", # Specific constrain\n",
    ")\n",
    "chat = client.chats.create(model = main_model, config = chat_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538e3b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "Response:  Hi! Is there anything specific you'd like to talk about or any help I can offer? If not, that's perfectly okay too! ðŸ˜Š\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Waiting prompt: \")\n",
    "print(prompt)\n",
    "\n",
    "while prompt != \"close\":\n",
    "    response = chat.send_message(prompt)\n",
    "    print(\"Response: \",response.text)\n",
    "    print(\"\\n\")\n",
    "    prompt = input(\"Waiting prompt: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f821cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Hi there! How can I help you today?\\n')], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Hey! What can I do for you?\\n')], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text=\"Hello! Is there anything specific you'd like to talk about or need help with? Just let me know!\\n\")], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text=\"Okay, I understand you're saying hi! ðŸ˜Š Is there anything you'd like to ask me, or anything I can help you with? Otherwise, I can just say hi back!\\n\")], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Hi! ðŸ‘‹\\n')], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Hello! Is there something you need or want to talk about?\\n')], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text=\"Hi! ðŸ‘‹ How's it going? Is there anything I can assist you with?\\n\")], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Hi! How can I help you today? Just saying \"hi\" is fine, but I want to make sure you get the most out of our interaction! Let me know if you have any questions, need information, or just want to chat.\\n')], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Hi! ðŸ‘‹\\n')], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='Hello! How are you doing?\\n')], role='model'),\n",
       " UserContent(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text='hi')], role='user'),\n",
       " Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text=\"Hi! Is there anything specific you'd like to talk about or any help I can offer? If not, that's perfectly okay too! ðŸ˜Š\\n\")], role='model')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfcb416",
   "metadata": {},
   "source": [
    "## Creating a second chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c84354",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_config_2 = types.GenerateContentConfig(\n",
    "    system_instruction = \"You are an expert in microbial ecology and answers questions objectively and precise.\"\n",
    ")\n",
    "chat_2 = client.chats.create(model=main_model, config=chat_config_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d84eaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A microbe, or microorganism, is a microscopic organism. These organisms are generally too small to be seen with the naked eye and include bacteria, archaea, fungi, protists, and viruses. Microbes can exist in single-celled form or in colonies.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat_2.send_message(\"What is a microbe?\")\n",
    "\n",
    "response.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
